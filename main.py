"""
Main pipeline script for GNSS error forecasting
"""
import argparse
import logging
from pathlib import Path

from src.utils import setup_logging, create_output_dirs, save_model_params, log_environment_info
from src.preprocess import preprocess_pipeline
from src.kalman_filter import build_state_matrices, run_kalman_forward
from src.tune import tune_q_r_gridsearch
from src.predict import generate_all_predictions
from src.evaluate import evaluate_all_satellites, generate_all_plots

def train_all_satellites(satellites_data, output_dir='models'):
    """Train Kalman filters for all satellites"""
    logger = logging.getLogger(__name__)
    logger.info("\n" + "="*60)
    logger.info("TRAINING KALMAN FILTERS")
    logger.info("="*60)
    
    trained_models = {}
    
    for sat_id, data in satellites_data.items():
        try:
            logger.info(f"\nTraining {sat_id}...")
            
            df_train = data['train']
            
            # Tune Q and R
            params = tune_q_r_gridsearch(df_train)
            
            # Save parameters
            save_model_params(sat_id, params, output_dir)
            
            trained_models[sat_id] = params
            
            logger.info(f"[OK] {sat_id} training complete")
        
        except Exception as e:
            logger.error(f"[ERROR] Training failed for {sat_id}: {e}")
            continue
    
    logger.info(f"\n[OK] Trained {len(trained_models)} satellites")
    
    return trained_models

def generate_readme(satellites_data, metrics, output_file='outputs/README_autogenerated.txt'):
    """Generate README with instructions"""
    import datetime
    num_satellites = len(satellites_data)
    
    readme_content = f"""
====================================================
   GNSS ERROR FORECASTING - KALMAN FILTER PIPELINE
====================================================

Satellites Processed: {num_satellites}
Training Period: Days 1-7
Forecast Period: Day 8 (96 x 15-min intervals)

OUTPUT FILES:
  - outputs/predictions_day8_geo.csv
  - outputs/predictions_day8_meo.csv
  - models/kalman_params_*.pkl
  - results/metrics_summary.json
  - results/figures/*.png

HOW TO RUN:
  python main.py --mode all --data-folder data

Generated: {datetime.datetime.now().isoformat()}
"""
    
    Path(output_file).parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(readme_content)
    logging.info(f"Saved README to {output_file}")

def main():
    """Main pipeline execution"""
    parser = argparse.ArgumentParser(description='GNSS Error Forecasting Pipeline')
    parser.add_argument('--data-folder', type=str, default='data', help='Data folder path')
    parser.add_argument('--mode', type=str, default='all', 
                       choices=['all', 'tune', 'forecast', 'evaluate'],
                       help='Pipeline mode')
    parser.add_argument('--out-dir', type=str, default='outputs', help='Output directory')
    parser.add_argument('--sat-list', type=str, nargs='+', help='Specific satellites to process')
    
    args = parser.parse_args()
    
    # Setup
    create_output_dirs()
    logger = setup_logging(f'{args.out_dir}/pipeline.log')
    
    logger.info("="*60)
    logger.info("GNSS ERROR FORECASTING PIPELINE")
    logger.info("="*60)
    logger.info(f"Mode: {args.mode}")
    logger.info(f"Data folder: {args.data_folder}")
    
    # Log environment
    log_environment_info()
    
    # Preprocess data
    satellites_data = preprocess_pipeline(args.data_folder)
    
    if not satellites_data:
        logger.error("No satellites data loaded. Exiting.")
        return
    
    # Filter satellites if specified
    if args.sat_list:
        satellites_data = {k: v for k, v in satellites_data.items() if k in args.sat_list}
    
    # Execute based on mode
    if args.mode in ['all', 'tune']:
        trained_models = train_all_satellites(satellites_data, 'models')
    
    if args.mode in ['all', 'forecast']:
        predictions = generate_all_predictions(satellites_data, 'models', args.out_dir)
    else:
        predictions = None
    
    if args.mode in ['all', 'evaluate'] and predictions:
        metrics = evaluate_all_satellites(predictions, satellites_data)
        generate_all_plots(predictions, satellites_data)
    else:
        metrics = None
    
    # Generate README
    generate_readme(satellites_data, metrics, f'{args.out_dir}/README_autogenerated.txt')
    
    # Final summary
    logger.info("\n" + "="*60)
    logger.info("PIPELINE COMPLETE")
    logger.info("="*60)
    logger.info(f"[OK] Processed {len(satellites_data)} satellites")
    logger.info(f"Outputs: {args.out_dir}/, models/, results/")
    logger.info("="*60)

if __name__ == '__main__':
    main()
